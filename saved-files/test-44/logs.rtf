{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 steps: 2450, episodes: 50, mean episode reward: -302.4094038755664, time: 15.392\
steps: 4950, episodes: 100, mean episode reward: -290.0940902788968, time: 15.04\
steps: 7450, episodes: 150, mean episode reward: -282.87034987562976, time: 15.1\
steps: 9950, episodes: 200, mean episode reward: -321.30868995057676, time: 15.636\
steps: 12450, episodes: 250, mean episode reward: -304.6033965336629, time: 15.016\
steps: 14950, episodes: 300, mean episode reward: -310.27678298778227, time: 14.555\
steps: 17450, episodes: 350, mean episode reward: -328.03559400521, time: 14.521\
steps: 19950, episodes: 400, mean episode reward: -314.75546916018965, time: 15.572\
steps: 22450, episodes: 450, mean episode reward: -306.1635106345168, time: 14.624\
steps: 24950, episodes: 500, mean episode reward: -311.95953787985474, time: 14.674\
steps: 27450, episodes: 550, mean episode reward: -303.03800663405195, time: 14.472\
steps: 29950, episodes: 600, mean episode reward: -285.07513495867477, time: 14.531\
steps: 32450, episodes: 650, mean episode reward: -322.2563728070767, time: 14.663\
steps: 34950, episodes: 700, mean episode reward: -261.99684317110695, time: 14.669\
steps: 37450, episodes: 750, mean episode reward: -298.56877379034063, time: 14.596\
steps: 39950, episodes: 800, mean episode reward: -282.8877987764269, time: 14.548\
steps: 42450, episodes: 850, mean episode reward: -331.22238965183084, time: 14.772\
steps: 44950, episodes: 900, mean episode reward: -275.7066921592523, time: 14.585\
steps: 47450, episodes: 950, mean episode reward: -303.9971251107602, time: 14.576\
steps: 49950, episodes: 1000, mean episode reward: -318.21750846808334, time: 14.74\
steps: 52450, episodes: 1050, mean episode reward: -561.8408806253367, time: 16.586\
steps: 54950, episodes: 1100, mean episode reward: -258.4124039364969, time: 16.863\
steps: 57450, episodes: 1150, mean episode reward: -103.78262666400049, time: 16.696\
steps: 59950, episodes: 1200, mean episode reward: -247.704552037552, time: 16.102\
steps: 62450, episodes: 1250, mean episode reward: -253.25476241476804, time: 16.598\
steps: 64950, episodes: 1300, mean episode reward: -208.1122674062966, time: 16.409\
steps: 67450, episodes: 1350, mean episode reward: -165.35157643923182, time: 16.206\
steps: 69950, episodes: 1400, mean episode reward: -61.48743713060116, time: 16.286\
steps: 72450, episodes: 1450, mean episode reward: -46.058611998349264, time: 16.147\
steps: 74950, episodes: 1500, mean episode reward: -278.0849204358676, time: 16.37\
steps: 77450, episodes: 1550, mean episode reward: -270.8225999785551, time: 16.209\
steps: 79950, episodes: 1600, mean episode reward: -67.75875311314977, time: 16.151\
steps: 82450, episodes: 1650, mean episode reward: -46.87197398984403, time: 16.356\
steps: 84950, episodes: 1700, mean episode reward: -54.1987259329574, time: 16.168\
steps: 87450, episodes: 1750, mean episode reward: -51.38938113719211, time: 16.333\
steps: 89950, episodes: 1800, mean episode reward: -48.61162409395164, time: 16.191\
steps: 92450, episodes: 1850, mean episode reward: -46.328075909764266, time: 16.167\
steps: 94950, episodes: 1900, mean episode reward: -38.21322517291062, time: 16.102\
steps: 97450, episodes: 1950, mean episode reward: -35.7926349925775, time: 16.421\
steps: 99950, episodes: 2000, mean episode reward: -41.10609575731815, time: 16.433\
steps: 102450, episodes: 2050, mean episode reward: -49.37423259001422, time: 16.138\
steps: 104950, episodes: 2100, mean episode reward: -62.620545508757694, time: 16.162\
steps: 107450, episodes: 2150, mean episode reward: -53.103829733872125, time: 16.184\
steps: 109950, episodes: 2200, mean episode reward: -58.924907952279334, time: 16.345\
steps: 112450, episodes: 2250, mean episode reward: -47.72626325816581, time: 16.145\
steps: 114950, episodes: 2300, mean episode reward: -44.89574624845361, time: 16.169\
steps: 117450, episodes: 2350, mean episode reward: -41.8865042925926, time: 16.276\
steps: 119950, episodes: 2400, mean episode reward: -41.899847972206175, time: 17.53\
steps: 122450, episodes: 2450, mean episode reward: -31.99892713851877, time: 17.311\
steps: 124950, episodes: 2500, mean episode reward: -25.229344385227375, time: 17.621\
steps: 127450, episodes: 2550, mean episode reward: -20.786781087859364, time: 17.343\
steps: 129950, episodes: 2600, mean episode reward: -22.954958838687148, time: 18.478\
steps: 132450, episodes: 2650, mean episode reward: -22.418728453572324, time: 17.293\
steps: 134950, episodes: 2700, mean episode reward: -22.52780748587135, time: 17.329\
steps: 137450, episodes: 2750, mean episode reward: -21.61541846565813, time: 16.369\
steps: 139950, episodes: 2800, mean episode reward: -20.964157125404668, time: 16.304\
steps: 142450, episodes: 2850, mean episode reward: -20.19681230502094, time: 16.116\
steps: 144950, episodes: 2900, mean episode reward: -19.973322111724872, time: 16.785\
steps: 147450, episodes: 2950, mean episode reward: -20.362155903355532, time: 16.199\
steps: 149950, episodes: 3000, mean episode reward: -20.13702569888174, time: 16.114\
steps: 152450, episodes: 3050, mean episode reward: -18.25234169212629, time: 16.169\
steps: 154950, episodes: 3100, mean episode reward: -18.940653672638994, time: 16.144\
steps: 157450, episodes: 3150, mean episode reward: -20.04129603730469, time: 16.162\
steps: 159950, episodes: 3200, mean episode reward: -19.406207418945097, time: 16.11\
steps: 162450, episodes: 3250, mean episode reward: -18.859049955374417, time: 18.383\
steps: 164950, episodes: 3300, mean episode reward: -18.652163704067092, time: 16.403\
steps: 167450, episodes: 3350, mean episode reward: -18.88510083048792, time: 16.45\
steps: 169950, episodes: 3400, mean episode reward: -18.22195418530003, time: 16.375\
steps: 172450, episodes: 3450, mean episode reward: -17.87949019718279, time: 16.85\
steps: 174950, episodes: 3500, mean episode reward: -17.843388781625485, time: 16.361}